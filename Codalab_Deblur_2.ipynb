{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 10867924,
          "sourceType": "datasetVersion",
          "datasetId": 6751605
        },
        {
          "sourceId": 11023362,
          "sourceType": "datasetVersion",
          "datasetId": 6864488
        }
      ],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Codalab Deblur 2",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "anettvarghese_highrev_path = kagglehub.dataset_download('anettvarghese/highrev')\n",
        "lei0331_highrev_testset_path = kagglehub.dataset_download('lei0331/highrev-testset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "Em1qyhSJCSqH"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install torch torchvision scikit-image\n",
        "!pip install --upgrade matplotlib\n",
        "\n",
        "# Set environment variable to reduce memory fragmentation\n",
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "# Import libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from skimage.metrics import peak_signal_noise_ratio as compute_psnr\n",
        "from skimage.metrics import structural_similarity as compute_ssim\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "import time\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "def display_gpu_memory():\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"GPU memory allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GiB\")\n",
        "        print(f\"GPU memory reserved: {torch.cuda.memory_reserved() / 1024**3:.2f} GiB\")\n",
        "\n",
        "# Function to convert raw events to voxel grid\n",
        "def create_voxel_grid(x, y, timestamps, polarity, num_bins=5, height=128, width=128):\n",
        "    grid = np.zeros((num_bins, height, width), dtype=np.float32)\n",
        "    if timestamps.size > 0:\n",
        "        t_min, t_max = timestamps.min(), timestamps.max()\n",
        "        t_normalized = (timestamps - t_min) / (t_max - t_min) * (num_bins - 1) if t_max > t_min else np.zeros_like(timestamps)\n",
        "\n",
        "        for i in range(len(x)):\n",
        "            xi, yi = int(x[i]), int(y[i])\n",
        "            ti = int(t_normalized[i])\n",
        "            if 0 <= xi < width and 0 <= yi < height and 0 <= ti < num_bins:\n",
        "                grid[ti, yi, xi] += polarity[i]\n",
        "    return grid\n",
        "\n",
        "# Define ConvBlock with Dropout\n",
        "class ConvLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dropout_rate=0.1):\n",
        "        super(ConvLayer, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.dropout = nn.Dropout2d(dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "class AttentionModule(nn.Module):\n",
        "    def __init__(self, channels, num_heads=4):\n",
        "        super(AttentionModule, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = channels // num_heads\n",
        "        assert self.head_dim * num_heads == channels, \"channels must be divisible by num_heads\"\n",
        "\n",
        "        self.query_conv = nn.Conv2d(channels, channels, kernel_size=1)\n",
        "        self.key_conv = nn.Conv2d(channels, channels, kernel_size=1)\n",
        "        self.value_conv = nn.Conv2d(channels, channels, kernel_size=1)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "        self.out_conv = nn.Conv2d(channels, channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, img_features, event_features):\n",
        "        batch, channels, height, width = img_features.size()\n",
        "\n",
        "        query = self.query_conv(img_features).view(batch, self.num_heads, self.head_dim, height * width)\n",
        "        key = self.key_conv(event_features).view(batch, self.num_heads, self.head_dim, height * width)\n",
        "        value = self.value_conv(event_features).view(batch, self.num_heads, self.head_dim, height * width)\n",
        "\n",
        "        query = query.permute(0, 1, 3, 2)  # (batch, heads, H*W, head_dim)\n",
        "        key = key  # (batch, heads, head_dim, H*W)\n",
        "        value = value  # (batch, heads, head_dim, H*W)\n",
        "\n",
        "        attention = self.softmax(torch.matmul(query, key) / (self.head_dim ** 0.5))  # (batch, heads, H*W, H*W)\n",
        "        out = torch.matmul(attention, value.permute(0, 1, 3, 2))  # (batch, heads, H*W, head_dim)\n",
        "        out = out.permute(0, 1, 3, 2).contiguous().view(batch, channels, height, width)\n",
        "\n",
        "        out = self.out_conv(out)\n",
        "        return out + img_features\n",
        "\n",
        "class DeblurNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, event_channels=5, out_channels=3):\n",
        "        super(DeblurNet, self).__init__()\n",
        "        # Encoder\n",
        "        self.img_conv1 = ConvLayer(in_channels, 128)\n",
        "        self.evt_conv1 = ConvLayer(event_channels, 128)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.img_conv2 = ConvLayer(128, 256)\n",
        "        self.evt_conv2 = ConvLayer(128, 256)\n",
        "\n",
        "        # Attention\n",
        "        self.attention1 = AttentionModule(128, num_heads=4)\n",
        "        self.attention2 = AttentionModule(256, num_heads=4)\n",
        "\n",
        "        # Residual Blocks\n",
        "        self.res_blocks1 = nn.Sequential(\n",
        "            ConvLayer(128, 128),\n",
        "            ConvLayer(128, 128),\n",
        "            ConvLayer(128, 128),\n",
        "        )\n",
        "        self.res_blocks2 = nn.Sequential(\n",
        "            ConvLayer(256, 256),\n",
        "            ConvLayer(256, 256),\n",
        "            ConvLayer(256, 256),\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.upconv = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.final_conv = nn.Conv2d(128, out_channels, kernel_size=3, padding=1)\n",
        "\n",
        "    def forward(self, blur_img, event_data):\n",
        "        # Encoder\n",
        "        img1 = self.img_conv1(blur_img)\n",
        "        evt1 = self.evt_conv1(event_data)\n",
        "        fused1 = self.attention1(img1, evt1)\n",
        "        fused1 = self.res_blocks1(fused1)\n",
        "\n",
        "        img2 = self.pool(fused1)\n",
        "        evt2 = self.pool(evt1)\n",
        "        img2 = self.img_conv2(img2)\n",
        "        evt2 = self.evt_conv2(evt2)\n",
        "        fused2 = self.attention2(img2, evt2)\n",
        "        fused2 = self.res_blocks2(fused2)\n",
        "\n",
        "        # Decoder\n",
        "        up = self.upconv(fused2)\n",
        "        up = up + fused1  # Skip connection\n",
        "        deblurred = self.final_conv(up)\n",
        "        return deblurred\n",
        "\n",
        "# Custom Dataset for HighREV (Training/Validation)\n",
        "class HighREVDataset(Dataset):\n",
        "    def __init__(self, data_dir, phase='train', target_size=(128, 128), num_bins=5):\n",
        "        self.data_dir = os.path.join(data_dir, phase)\n",
        "        self.blur_dir = os.path.join(self.data_dir, 'blur')\n",
        "        self.sharp_dir = os.path.join(self.data_dir, 'sharp')\n",
        "        self.event_dir = os.path.join(self.data_dir, 'event')\n",
        "        self.target_size = target_size\n",
        "        self.num_bins = num_bins\n",
        "\n",
        "        self.blur_files = sorted(os.listdir(self.blur_dir))\n",
        "        self.event_files = sorted(os.listdir(self.event_dir))\n",
        "\n",
        "        self.file_map = {}\n",
        "        for blur_file in self.blur_files:\n",
        "            blur_base = os.path.splitext(blur_file)[0]\n",
        "            for event_file in self.event_files:\n",
        "                if blur_base in event_file:\n",
        "                    self.file_map[blur_file] = event_file\n",
        "                    break\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.blur_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        blur_file = self.blur_files[idx]\n",
        "        blur_path = os.path.join(self.blur_dir, blur_file)\n",
        "        blur_img = cv2.imread(blur_path)\n",
        "        if blur_img is None:\n",
        "            raise FileNotFoundError(f\"Could not load blur image: {blur_path}\")\n",
        "        original_height, original_width = blur_img.shape[:2]\n",
        "        blur_img = cv2.cvtColor(blur_img, cv2.COLOR_BGR2RGB)\n",
        "        blur_img = cv2.resize(blur_img, (self.target_size[1], self.target_size[0]))\n",
        "        blur_img = blur_img.transpose(2, 0, 1) / 255.0\n",
        "        blur_img = torch.FloatTensor(blur_img)\n",
        "\n",
        "        sharp_path = os.path.join(self.sharp_dir, blur_file)\n",
        "        sharp_img = cv2.imread(sharp_path)\n",
        "        if sharp_img is None:\n",
        "            raise FileNotFoundError(f\"Could not load sharp image: {sharp_path}\")\n",
        "        sharp_img = cv2.cvtColor(sharp_img, cv2.COLOR_BGR2RGB)\n",
        "        sharp_img = cv2.resize(sharp_img, (self.target_size[1], self.target_size[0]))\n",
        "        sharp_img = sharp_img.transpose(2, 0, 1) / 255.0\n",
        "        sharp_img = torch.FloatTensor(sharp_img)\n",
        "\n",
        "        event_file = self.file_map[blur_file]\n",
        "        event_path = os.path.join(self.event_dir, event_file)\n",
        "        npz_data = np.load(event_path)\n",
        "        x = npz_data['x']\n",
        "        y = npz_data['y']\n",
        "        timestamps = npz_data['timestamp']\n",
        "        polarity = npz_data['polarity']\n",
        "\n",
        "        original_height, original_width = cv2.imread(blur_path).shape[:2]\n",
        "        x = (x / original_width) * self.target_size[1]\n",
        "        y = (y / original_height) * self.target_size[0]\n",
        "\n",
        "        event_data = create_voxel_grid(\n",
        "            x, y, timestamps, polarity, self.num_bins, self.target_size[0], self.target_size[1]\n",
        "        )\n",
        "        if idx == 0:\n",
        "            print(f\"Event data shape: {event_data.shape}\")\n",
        "            print(f\"Blurry image shape: {blur_img.shape}\")\n",
        "        event_data = torch.FloatTensor(event_data)\n",
        "\n",
        "        return blur_img, event_data, sharp_img, blur_file, (int(original_width), int(original_height))\n",
        "\n",
        "# Custom Dataset for Test (No Sharp Images)\n",
        "class HighREVTestDataset(Dataset):\n",
        "    def __init__(self, data_dir, target_size=(128, 128), num_bins=5):\n",
        "        self.data_dir = data_dir\n",
        "        self.blur_dir = os.path.join(self.data_dir, 'blur')\n",
        "        self.event_dir = os.path.join(self.data_dir, 'event')\n",
        "        self.target_size = target_size\n",
        "        self.num_bins = num_bins\n",
        "\n",
        "        self.blur_files = sorted(os.listdir(self.blur_dir))\n",
        "        self.event_files = sorted(os.listdir(self.event_dir))\n",
        "\n",
        "        self.file_map = {}\n",
        "        for blur_file in self.blur_files:\n",
        "            blur_base = os.path.splitext(blur_file)[0]\n",
        "            for event_file in self.event_files:\n",
        "                if blur_base in event_file:\n",
        "                    self.file_map[blur_file] = event_file\n",
        "                    break\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.blur_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        blur_file = self.blur_files[idx]\n",
        "        blur_path = os.path.join(self.blur_dir, blur_file)\n",
        "        blur_img = cv2.imread(blur_path)\n",
        "        if blur_img is None:\n",
        "            raise FileNotFoundError(f\"Could not load blur image: {blur_path}\")\n",
        "        original_height, original_width = blur_img.shape[:2]\n",
        "        blur_img = cv2.cvtColor(blur_img, cv2.COLOR_BGR2RGB)\n",
        "        blur_img = cv2.resize(blur_img, (self.target_size[1], self.target_size[0]))\n",
        "        blur_img = blur_img.transpose(2, 0, 1) / 255.0\n",
        "        blur_img = torch.FloatTensor(blur_img)\n",
        "\n",
        "        event_file = self.file_map[blur_file]\n",
        "        event_path = os.path.join(self.event_dir, event_file)\n",
        "        npz_data = np.load(event_path)\n",
        "        x = npz_data['x']\n",
        "        y = npz_data['y']\n",
        "        timestamps = npz_data['timestamp']\n",
        "        polarity = npz_data['polarity']\n",
        "\n",
        "        original_height, original_width = cv2.imread(blur_path).shape[:2]\n",
        "        x = (x / original_width) * self.target_size[1]\n",
        "        y = (y / original_height) * self.target_size[0]\n",
        "\n",
        "        event_data = create_voxel_grid(\n",
        "            x, y, timestamps, polarity, self.num_bins, self.target_size[0], self.target_size[1]\n",
        "        )\n",
        "        if idx == 0:\n",
        "            print(f\"Test event data shape: {event_data.shape}\")\n",
        "            print(f\"Test blurry image shape: {blur_img.shape}\")\n",
        "        event_data = torch.FloatTensor(event_data)\n",
        "\n",
        "        original_size = (int(original_width), int(original_height))\n",
        "        print(f\"Dataset item {idx}, blur_file: {blur_file}, original_size: {original_size}\")\n",
        "        return blur_img, event_data, blur_file, original_size\n",
        "\n",
        "# Custom collate function to preserve original_size as a list of tuples\n",
        "def custom_collate_fn(batch):\n",
        "    blurry, events, blur_filename, original_size = zip(*batch)\n",
        "    return (\n",
        "        torch.stack(blurry),\n",
        "        torch.stack(events),\n",
        "        list(blur_filename),\n",
        "        list(original_size)  # Preserve original_size as a list of tuples\n",
        "    )\n",
        "\n",
        "# Enable mixed precision training\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = DeblurNet().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-5)\n",
        "scaler = GradScaler()\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=12)\n",
        "\n",
        "train_dataset = HighREVDataset('/kaggle/input/highrev/HighREV', phase='train', target_size=(128, 128))\n",
        "val_dataset = HighREVDataset('/kaggle/input/highrev/HighREV', phase='val', target_size=(128, 128))\n",
        "test_dataset = HighREVTestDataset('/kaggle/input/highrev-testset/HighREV_test/HighREV_test', target_size=(128, 128))\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=2, pin_memory=True, collate_fn=custom_collate_fn)\n",
        "\n",
        "num_epochs = 6\n",
        "accumulation_steps = 2\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    optimizer.zero_grad()\n",
        "    for i, (blurry, events, sharp, _, _) in enumerate(train_loader):\n",
        "        blurry, events, sharp = blurry.to(device), events.to(device), sharp.to(device)\n",
        "\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            outputs = model(blurry, events)\n",
        "            loss = criterion(outputs, sharp) / accumulation_steps\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        if (i + 1) % accumulation_steps == 0:\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "        running_loss += loss.item() * accumulation_steps\n",
        "        if i % 100 == 99:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {running_loss/100:.4f}')\n",
        "            running_loss = 0.0\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    scheduler.step()\n",
        "    print(f\"Epoch {epoch+1}, Learning Rate: {scheduler.get_last_lr()[0]:.6f}\")\n",
        "    display_gpu_memory()\n",
        "\n",
        "# Save checkpoint\n",
        "checkpoint = {\n",
        "    'epoch': num_epochs,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'scheduler_state_dict': scheduler.state_dict(),\n",
        "    'scaler_state_dict': scaler.state_dict(),\n",
        "}\n",
        "checkpoint_path = '/kaggle/working/checkpoint_epoch_6.pth'\n",
        "torch.save(checkpoint, checkpoint_path)\n",
        "print(f\"Checkpoint saved at: {checkpoint_path}\")\n",
        "\n",
        "# Evaluation on validation set for metrics\n",
        "model.eval()\n",
        "psnr_scores = []\n",
        "ssim_scores = []\n",
        "val_time = 0.0\n",
        "print(f\"Evaluating {len(val_loader)} validation images for metrics...\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (blurry, events, sharp, blur_filename, _) in enumerate(val_loader):\n",
        "        start_time = time.time()\n",
        "        blurry, events, sharp = blurry.to(device), events.to(device), sharp.to(device)\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            deblurred = model(blurry, events)\n",
        "\n",
        "        deblurred_np = deblurred.cpu().numpy()\n",
        "        sharp_np = sharp.cpu().numpy()\n",
        "        blurry_np = blurry.cpu().numpy()\n",
        "\n",
        "        for j in range(deblurred_np.shape[0]):\n",
        "            deblurred_img = deblurred_np[j].transpose(1, 2, 0).astype(np.float32)\n",
        "            sharp_img = sharp_np[j].transpose(1, 2, 0).astype(np.float32)\n",
        "\n",
        "            deblurred_img = np.clip(deblurred_img, 0, 1)\n",
        "            sharp_img = np.clip(sharp_img, 0, 1)\n",
        "\n",
        "            if deblurred_img.shape[0] < 7 or deblurred_img.shape[1] < 7:\n",
        "                print(f\"Warning: Validation image {blur_filename[j]} too small for SSIM\")\n",
        "                psnr_score = compute_psnr(sharp_img, deblurred_img, data_range=1.0)\n",
        "                ssim_score = 0\n",
        "            else:\n",
        "                psnr_score = compute_psnr(sharp_img, deblurred_img, data_range=1.0)\n",
        "                ssim_score = compute_ssim(sharp_img, deblurred_img, data_range=1.0, multichannel=True, channel_axis=2)\n",
        "            psnr_scores.append(psnr_score)\n",
        "            ssim_scores.append(ssim_score)\n",
        "\n",
        "        end_time = time.time()\n",
        "        val_time += end_time - start_time\n",
        "\n",
        "        del deblurred, blurry, events, sharp, deblurred_np, sharp_np, blurry_np\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "# Process test set and save outputs\n",
        "total_time = 0.0\n",
        "output_dir = '/kaggle/working/test_output_epoch_6'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "print(f\"Processing {len(test_loader)} test images...\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (blurry, events, blur_filename, original_size) in enumerate(test_loader):\n",
        "        start_time = time.time()\n",
        "        blurry, events = blurry.to(device), events.to(device)\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            deblurred = model(blurry, events)\n",
        "\n",
        "        deblurred_np = deblurred.cpu().numpy()\n",
        "        blurry_np = blurry.cpu().numpy()\n",
        "\n",
        "        for j in range(deblurred_np.shape[0]):\n",
        "            deblurred_img = deblurred_np[j].transpose(1, 2, 0).astype(np.float32)\n",
        "            print(f\"Processing test image {blur_filename[j]}\")\n",
        "            print(f\"deblurred_img shape: {deblurred_img.shape}, dtype: {deblurred_img.dtype}, min: {deblurred_img.min()}, max: {deblurred_img.max()}\")\n",
        "\n",
        "            if deblurred_img.size == 0 or deblurred_img.shape[0] == 0 or deblurred_img.shape[1] == 0:\n",
        "                print(f\"Warning: Invalid deblurred_img for {blur_filename[j]}, skipping\")\n",
        "                continue\n",
        "\n",
        "            deblurred_img = np.clip(deblurred_img, 0, 1)\n",
        "\n",
        "            # Debug and validate original_size\n",
        "            print(f\"Batch {i}, j={j}, original_size[{j}]: {original_size[j]}\")\n",
        "            if not isinstance(original_size[j], (tuple, list)) or len(original_size[j]) != 2:\n",
        "                raise ValueError(f\"Invalid original_size for {blur_filename[j]}: {original_size[j]}. Expected a 2-element tuple (width, height).\")\n",
        "\n",
        "            original_width = int(original_size[j][0])\n",
        "            original_height = int(original_size[j][1])\n",
        "\n",
        "            deblurred_resized = cv2.resize(deblurred_img, (original_width, original_height), interpolation=cv2.INTER_LINEAR)\n",
        "            print(f\"deblurred_resized shape: {deblurred_resized.shape}\")\n",
        "\n",
        "            blurred = cv2.GaussianBlur(deblurred_resized, (5, 5), 0)\n",
        "            deblurred_resized = cv2.addWeighted(deblurred_resized, 1.5, blurred, -0.5, 0)\n",
        "\n",
        "            deblurred_img = (deblurred_resized * 255).astype(np.uint8)\n",
        "            print(f\"deblurred_img shape before save: {deblurred_img.shape}\")\n",
        "            deblurred_img = cv2.cvtColor(deblurred_img, cv2.COLOR_RGB2BGR)\n",
        "            output_path = os.path.join(output_dir, blur_filename[j])\n",
        "            print(f\"Saving deblurred test image to: {output_path}\")\n",
        "            success = cv2.imwrite(output_path, deblurred_img, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
        "            if not success:\n",
        "                print(f\"Failed to save {output_path}\")\n",
        "            else:\n",
        "                print(f\"Successfully saved {output_path}\")\n",
        "\n",
        "        end_time = time.time()\n",
        "        processing_time = end_time - start_time\n",
        "        total_time += processing_time\n",
        "        print(f\"Processing time for test batch {i+1}: {processing_time:.2f} seconds\")\n",
        "\n",
        "        if i == 0:\n",
        "            try:\n",
        "                plt.figure(figsize=(10, 5))\n",
        "                plt.subplot(1, 2, 1)\n",
        "                plt.title(\"Blurry Test Image\")\n",
        "                plt.imshow(blurry_np[0].transpose(1, 2, 0))\n",
        "                plt.axis('off')\n",
        "                plt.subplot(1, 2, 2)\n",
        "                plt.title(\"Deblurred Test Image\")\n",
        "                plt.imshow(deblurred_resized)\n",
        "                plt.axis('off')\n",
        "                plt.show()\n",
        "            except Exception as e:\n",
        "                print(f\"Error during visualization: {e}\")\n",
        "\n",
        "        del deblurred, blurry, events, deblurred_np, blurry_np, deblurred_resized, deblurred_img\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "        display_gpu_memory()\n",
        "\n",
        "# Summary\n",
        "avg_psnr = np.mean(psnr_scores) if psnr_scores else 0.0\n",
        "avg_ssim = np.mean(ssim_scores) if ssim_scores else 0.0\n",
        "avg_time_per_image = total_time / (len(test_loader.dataset)) if len(test_loader.dataset) > 0 else 0.0\n",
        "avg_val_time_per_image = val_time / len(val_loader.dataset) if len(val_loader.dataset) > 0 else 0.0\n",
        "print(f\"Average PSNR (Validation) after 6 epochs: {avg_psnr:.2f}\")\n",
        "print(f\"Average SSIM (Validation) after 6 epochs: {avg_ssim:.4f}\")\n",
        "print(f\"Average runtime per test image: {avg_time_per_image:.2f} seconds\")\n",
        "\n",
        "device_type = 0 if torch.cuda.is_available() and device.type == 'cuda' else 1\n",
        "extra_data = 0\n",
        "\n",
        "# Create readme.txt\n",
        "readme_content = f\"\"\"runtime per image [s] : {avg_time_per_image:.2f}\n",
        "CPU[1] / GPU[0] : {device_type}\n",
        "Extra Data [1] / No Extra Data [0] : {extra_data}\n",
        "Average PSNR (Validation) : {avg_psnr:.2f}\n",
        "Average SSIM (Validation) : {avg_ssim:.4f}\n",
        "Other description : Intermediate results after 6 epochs. Enhanced EFNet model with U-Net-like architecture and multi-head CrossModalAttention for event-based deblurring. Trained on HighREV training dataset with CosineAnnealingLR scheduling, lower learning rate (0.0005), and weight decay (1e-5). Batch size 1 with accumulation_steps=2 to simulate batch_size=2. Reduced num_bins to 5 for event data. Post-processing includes unsharp masking. Checkpoint saved at /kaggle/working/checkpoint_epoch_6.pth. Deblurred test images saved in /kaggle/working/test_output_epoch_6 as full-quality RGB PNGs at original resolution (1632x1224) with no compression.\n",
        "\"\"\"\n",
        "print(f\"Deblurred test images saved in: {output_dir}\")\n",
        "print(\"Check the Kaggle output section under '/kaggle/working/test_output_epoch_6' for images and readme.txt\")"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-21T12:28:30.554861Z",
          "iopub.execute_input": "2025-03-21T12:28:30.555088Z",
          "execution_failed": "2025-03-21T15:22:47.693Z"
        },
        "id": "w4-WjyHdCSqI"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}